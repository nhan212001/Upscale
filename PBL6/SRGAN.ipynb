{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZV0F5epTJ56l"
      },
      "outputs": [],
      "source": [
        "import cv2 \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import os \n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A--d8A1ZK0FM"
      },
      "outputs": [],
      "source": [
        "# path = '/content/drive/MyDrive/DATA_SRGAN /mirflickr25k.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9s2NYTliN-Er"
      },
      "outputs": [],
      "source": [
        "# !unzip '/content/drive/MyDrive/DATA_SRGAN /mirflickr25k.zip'  -d '/content/drive/MyDrive/DATA_SRGAN'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0axzSALLZcpD"
      },
      "outputs": [],
      "source": [
        "print(len(os.listdir('/PBL/PBL6/train')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i = 0\n",
        "imgs = []\n",
        "\n",
        "for img in os.listdir(\"/PBL/PBL6/train\"):\n",
        "    img = cv2.imread(\"/PBL/PBL6/train/\" + img )\n",
        "    img = np.array(img)\n",
        "    imgs.append(img)\n",
        "    i+=1\n",
        "    if i == 19:\n",
        "        break\n",
        "plt.figure(figsize=(20,10))\n",
        "for i in range(18):\n",
        "    plt.subplot(3,6,i+1)\n",
        "    plt.imshow(imgs[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sizes = set()\n",
        "i=0\n",
        "for img in os.listdir(\"/PBL/PBL6/train\"):\n",
        "    print(img)\n",
        "    try:\n",
        "        img_file = cv2.imread(\"/PBL/PBL6/train/\" + img )\n",
        "        # sizes.add((img.shape[0],img.shape[1]))\n",
        "        plt.subplot(2,1,1)\n",
        "        plt.plot(img_file.shape[0],img_file.shape[1],'.')\n",
        "        i+=1\n",
        "        # if img_file.shape[1] == 500 and img_file.shape[0]>=350 and img_file.shape[0]<=650:\n",
        "        #     cv2.imwrite(\"/PBL/PBL6/train/\" + img,img_file)\n",
        "        #     plt.subplot(2,1,2)\n",
        "        #     plt.plot(img_file.shape[0],img_file.shape[1],'.')\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "\n",
        "# print(len(os.listdir(\"/PBL/PBL6/train\")))\n",
        "print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_img = cv2.imread(\"/PBL/PBL6/train/ 2.jpg\")\n",
        "hr_img = cv2.resize(base_img, (128,128))\n",
        "lr_img = cv2.resize(base_img, (32,32))\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(base_img)\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(hr_img)\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(lr_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyDKoSeSg-My"
      },
      "outputs": [],
      "source": [
        "# os.makedirs('/PBL/PBL6/lr_images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYWsYhuFhj2a"
      },
      "outputs": [],
      "source": [
        "# os.makedirs('/PBL/PBL6/hr_images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHd4j88FfbMb",
        "outputId": "e70e2fc9-5f5a-4416-9879-079bbb2de33b"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViTg0agIKCsG"
      },
      "outputs": [],
      "source": [
        "train_dir = '/PBL/PBL6'\n",
        "i = 0 \n",
        "\n",
        "for img in os.listdir('/content/drive/MyDrive/images2'):\n",
        "\n",
        "  if img.endswith('.jpg'):\n",
        "    try:\n",
        "      img_array = cv2.imread(\"/content/drive/MyDrive/images2/\" + img)\n",
        "\n",
        "      img_array = cv2.resize(img_array, (128,128))\n",
        "      lr_img_array = cv2.resize(img_array,(32,32))\n",
        "      cv2.imwrite(train_dir+ \"/hr_images/\" + img, img_array)\n",
        "      cv2.imwrite(train_dir+ \"/lr_images/\"+ img, lr_img_array)\n",
        "    except:\n",
        "      continue\n",
        "  if i == 4000: \n",
        "    break \n",
        "  i +=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3eRy9IReSNb",
        "outputId": "cd5673ba-037b-47a1-a7ce-ed50b85e25ba"
      },
      "outputs": [],
      "source": [
        "print(len(os.listdir('/PBL/PBL6/lr_images')))\n",
        "print(len(os.listdir('/PBL/PBL6/hr_images')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fq5lU9bcqf8T"
      },
      "outputs": [],
      "source": [
        "lr_list = os.listdir(\"/PBL/PBL6/lr_images\")\n",
        "\n",
        "lr_images = []\n",
        "for img in lr_list:\n",
        "    img_lr = cv2.imread(\"/PBL/PBL6/lr_images/\" + img)\n",
        "    img_lr = cv2.cvtColor(img_lr, cv2.COLOR_BGR2RGB)\n",
        "    lr_images.append(img_lr)   \n",
        "\n",
        "\n",
        "hr_list = os.listdir(\"/PBL/PBL6/hr_images\")\n",
        "   \n",
        "hr_images = []\n",
        "for img in hr_list:\n",
        "    img_hr = cv2.imread(\"/PBL/PBL6/hr_images/\" + img)\n",
        "    img_hr = cv2.cvtColor(img_hr, cv2.COLOR_BGR2RGB)\n",
        "    hr_images.append(img_hr)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MP7Qnoo1xzlX"
      },
      "outputs": [],
      "source": [
        "lr_images = np.array(lr_images)\n",
        "hr_images = np.array(hr_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogDlSz2wubHm"
      },
      "outputs": [],
      "source": [
        "lr_images = lr_images / 255.\n",
        "hr_images = hr_images / 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_n7NBFV5ob-6"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import cv2 \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "from keras.models import Sequential \n",
        "from sklearn.model_selection import train_test_split \n",
        "from keras.layers import Conv2D, PReLU, BatchNormalization, Flatten \n",
        "from keras.layers import UpSampling2D, LeakyReLU, Dense, Input, add \n",
        "from keras.utils import plot_model \n",
        "from keras import Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axmVWKk0oghJ"
      },
      "outputs": [],
      "source": [
        "# define blocks to build the generator \n",
        "def res_block(ip):\n",
        "    \n",
        "    res_model = Conv2D(64, (3,3), padding = \"same\")(ip)\n",
        "    res_model = BatchNormalization(momentum = 0.5)(res_model)\n",
        "    res_model = PReLU(shared_axes = [1,2])(res_model)\n",
        "    \n",
        "    res_model = Conv2D(64, (3,3), padding = \"same\")(res_model)\n",
        "    res_model = BatchNormalization(momentum = 0.5)(res_model)\n",
        "    \n",
        "    return add([ip,res_model])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oMkuP7mogkH"
      },
      "outputs": [],
      "source": [
        "def upscale_block(ip):\n",
        "    \n",
        "    up_model = Conv2D(256, (3,3), padding=\"same\")(ip)\n",
        "    up_model = UpSampling2D( size = 2 )(up_model)\n",
        "    up_model = PReLU(shared_axes=[1,2])(up_model)\n",
        "    \n",
        "    return up_model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34S5m5kHogm7"
      },
      "outputs": [],
      "source": [
        "#Generator model\n",
        "def create_gen(gen_ip, num_res_block):\n",
        "    layers = Conv2D(64, (9,9), padding=\"same\")(gen_ip)\n",
        "    layers = PReLU(shared_axes=[1,2])(layers)\n",
        "\n",
        "    temp = layers\n",
        "\n",
        "    for i in range(num_res_block):\n",
        "        layers = res_block(layers)\n",
        "\n",
        "    layers = Conv2D(64, (3,3), padding=\"same\")(layers)\n",
        "    layers = BatchNormalization(momentum=0.5)(layers)\n",
        "    layers = add([layers,temp])\n",
        "\n",
        "    layers = upscale_block(layers)\n",
        "    layers = upscale_block(layers)\n",
        "\n",
        "    op = Conv2D(3, (9,9), padding=\"same\")(layers)\n",
        "\n",
        "    return Model(inputs=gen_ip, outputs=op)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAPJakwfogpx"
      },
      "outputs": [],
      "source": [
        "#Descriminator block that will be used to construct the discriminator\n",
        "def discriminator_block(ip, filters, strides=1, bn=True):\n",
        "    \n",
        "    disc_model = Conv2D(filters, (3,3), strides = strides, padding=\"same\")(ip)\n",
        "    \n",
        "    if bn:\n",
        "        disc_model = BatchNormalization( momentum=0.8 )(disc_model)\n",
        "    \n",
        "    disc_model = LeakyReLU( alpha=0.2 )(disc_model)\n",
        "    \n",
        "    return disc_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNlLTX3yqQ87"
      },
      "outputs": [],
      "source": [
        "#Descriminartor, as described in the original paper\n",
        "def create_disc(disc_ip):\n",
        "\n",
        "    df = 64\n",
        "    \n",
        "    d1 = discriminator_block(disc_ip, df, bn=False)\n",
        "    d2 = discriminator_block(d1, df, strides=2)\n",
        "    d3 = discriminator_block(d2, df*2)\n",
        "    d4 = discriminator_block(d3, df*2, strides=2)\n",
        "    d5 = discriminator_block(d4, df*4)\n",
        "    d6 = discriminator_block(d5, df*4, strides=2)\n",
        "    d7 = discriminator_block(d6, df*8)\n",
        "    d8 = discriminator_block(d7, df*8, strides=2)\n",
        "    \n",
        "    d8_5 = Flatten()(d8)\n",
        "    d9 = Dense(df*16)(d8_5)\n",
        "    d10 = LeakyReLU(alpha=0.2)(d9)\n",
        "    validity = Dense(1, activation='sigmoid')(d10)\n",
        "\n",
        "    return Model(disc_ip, validity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuhnmGM6qQ_i"
      },
      "outputs": [],
      "source": [
        "from keras.applications import VGG19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqaTV-EoqRCT"
      },
      "outputs": [],
      "source": [
        "def build_vgg(hr_shape):\n",
        "    \n",
        "    vgg = VGG19(weights=\"imagenet\",include_top=False, input_shape=hr_shape)\n",
        "    \n",
        "    return Model(inputs=vgg.inputs, outputs=vgg.layers[10].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gBnPv26qRFB"
      },
      "outputs": [],
      "source": [
        "#Combined model\n",
        "def create_comb(gen_model, disc_model, vgg, lr_ip, hr_ip):\n",
        "    gen_img = gen_model(lr_ip)\n",
        "    \n",
        "    gen_features = vgg(gen_img)\n",
        "    \n",
        "    disc_model.trainable = False\n",
        "    validity = disc_model(gen_img)\n",
        "    \n",
        "    return Model(inputs=[lr_ip, hr_ip], outputs=[validity, gen_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jE451uikqf-s"
      },
      "outputs": [],
      "source": [
        "# os.makedirs('/PBL/PBL6/Data_train_np')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMm3gycDqgBa"
      },
      "outputs": [],
      "source": [
        "# np.save('/PBL/PBL6/Data_train_np/lr_images.npy', lr_images)\n",
        "# np.save('/PBL/PBL6/Data_train_np/hr_images.npy', hr_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NG-B_vrfqgDp"
      },
      "outputs": [],
      "source": [
        "lr_images = np.load('/PBL/PBL6/Data_train_np/lr_images.npy')\n",
        "hr_images = np.load('/PBL//PBL6/Data_train_np/hr_images.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tNizCUXzRtv"
      },
      "outputs": [],
      "source": [
        "#Split to train and test\n",
        "lr_train, lr_test, hr_train, hr_test = train_test_split(lr_images, hr_images, \n",
        "                                                        test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('/PBL/PBL6/Data_train_np/lr_test_images.npy', lr_test)\n",
        "np.save('/PBL/PBL6/Data_train_np/hr_test_images.npy', hr_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr_test = np.load('/PBL/PBL6/Data_train_np/lr_test_images.npy')\n",
        "hr_test = np.load('/PBL//PBL6/Data_train_np/hr_test_images.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clDx3mjWzR1w"
      },
      "outputs": [],
      "source": [
        "hr_shape = (hr_train.shape[1], hr_train.shape[2], hr_train.shape[3])\n",
        "lr_shape = (lr_train.shape[1], lr_train.shape[2], lr_train.shape[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-GkixiFzeRO",
        "outputId": "8b5155e5-686a-4fa4-f8aa-fd6d2a5a7fc1"
      },
      "outputs": [],
      "source": [
        "print(hr_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pDOSwngzeTw"
      },
      "outputs": [],
      "source": [
        "lr_ip = Input(shape=lr_shape)\n",
        "hr_ip = Input(shape=hr_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrfHqm9qzeWz",
        "outputId": "986e1356-182d-409b-9824-58cf6db729ff"
      },
      "outputs": [],
      "source": [
        "generator = create_gen(lr_ip, num_res_block = 16)\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fj2pIKvzo_-"
      },
      "outputs": [],
      "source": [
        "discriminator = create_disc(hr_ip)\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Jp12HR0NzpCx",
        "outputId": "13d77848-c0ec-48aa-9438-caa236c7fcb5"
      },
      "outputs": [],
      "source": [
        "vgg = build_vgg((128,128,3))\n",
        "print(vgg.summary())\n",
        "vgg.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPhBZnN8zpFL"
      },
      "outputs": [],
      "source": [
        "gan_model = create_comb(generator, discriminator, vgg, lr_ip, hr_ip)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8l-LXiZzxgu"
      },
      "outputs": [],
      "source": [
        "gan_model.compile(loss=[\"binary_crossentropy\", \"mse\"], loss_weights=[1e-3, 1], optimizer=\"adam\")\n",
        "gan_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SjbdEm0Bvbc"
      },
      "outputs": [],
      "source": [
        "plot_model(gan_model,\"model_plot.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xODM4RRqzxkY"
      },
      "outputs": [],
      "source": [
        "batch_size = 1   \n",
        "train_lr_batches = []\n",
        "train_hr_batches = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXLbi9U7zxqt"
      },
      "outputs": [],
      "source": [
        "for it in range(int(hr_train.shape[0] / batch_size)):\n",
        "    start_idx = it * batch_size\n",
        "    end_idx = start_idx + batch_size\n",
        "    train_hr_batches.append(hr_train[start_idx:end_idx])\n",
        "    train_lr_batches.append(lr_train[start_idx:end_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfBj4GWUz-gn"
      },
      "outputs": [],
      "source": [
        "# os.makedirs(\"/PBL/PBL6/save_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoR_JxS2Xi1I"
      },
      "outputs": [],
      "source": [
        "# os.makedirs('/PBL/PBL6/save_loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NWn1nsAz-jW",
        "outputId": "f0bd5ade-26fa-4b4f-9e83-fd36d4b197c1"
      },
      "outputs": [],
      "source": [
        "save_path = \"/PBL/PBL6/save_model/\"\n",
        "save_path_loss = '/PBL/PBL6/save_loss/'\n",
        "epochs = 20 \n",
        "#Enumerate training over epochs\n",
        "for e in range(epochs):\n",
        "    \n",
        "    fake_label = np.zeros((batch_size, 1)) # Assign a label of 0 to all fake (generated images)\n",
        "    real_label = np.ones((batch_size,1)) # Assign a label of 1 to all real images.\n",
        "    \n",
        "    #Create empty lists to populate gen and disc losses. \n",
        "    g_losses = []\n",
        "    d_losses = []\n",
        "    \n",
        "    #Enumerate training over batches. \n",
        "    for b in tqdm(range(len(train_hr_batches))):\n",
        "        lr_imgs = train_lr_batches[b] #Fetch a batch of LR images for training\n",
        "        hr_imgs = train_hr_batches[b] #Fetch a batch of HR images for training\n",
        "        \n",
        "        fake_imgs = generator.predict_on_batch(lr_imgs) #Fake images\n",
        "        \n",
        "        #First, train the discriminator on fake and real HR images. \n",
        "        discriminator.trainable = True\n",
        "        d_loss_gen = discriminator.train_on_batch(fake_imgs, fake_label)\n",
        "        d_loss_real = discriminator.train_on_batch(hr_imgs, real_label)\n",
        "        \n",
        "        #Now, train the generator by fixing discriminator as non-trainable\n",
        "        discriminator.trainable = False\n",
        "        \n",
        "        #Average the discriminator loss, just for reporting purposes. \n",
        "        d_loss = 0.5 * np.add(d_loss_gen, d_loss_real) \n",
        "        \n",
        "        #Extract VGG features, to be used towards calculating loss\n",
        "        image_features = vgg.predict(hr_imgs)\n",
        "     \n",
        "        #Train the generator via GAN. \n",
        "        #Remember that we have 2 losses, adversarial loss and content (VGG) loss\n",
        "        g_loss, _, _ = gan_model.train_on_batch([lr_imgs, hr_imgs], [real_label, image_features])\n",
        "        \n",
        "        #Save losses to a list so we can average and report. \n",
        "        d_losses.append(d_loss)\n",
        "        g_losses.append(g_loss)\n",
        "        \n",
        "    #Convert the list of losses to an array to make it easy to average    \n",
        "    g_losses = np.array(g_losses)\n",
        "    d_losses = np.array(d_losses)\n",
        "    \n",
        "    #Calculate the average losses for generator and discriminator\n",
        "    g_loss = np.sum(g_losses, axis=0) / len(g_losses)\n",
        "    d_loss = np.sum(d_losses, axis=0) / len(d_losses)\n",
        "    \n",
        "    #Report the progress during training. \n",
        "    print(\"epoch:\", e+1 ,\"g_loss:\", g_loss, \"d_loss:\", d_loss)\n",
        "\n",
        "    if (e+1) % 2 == 0: #Change the frequency for model saving, if needed\n",
        "        #Save the generator after every n epochs (Usually 10 epochs)\n",
        "        generator.save(save_path + \"gen_e_\"+ str(e+1) +\".h5\")\n",
        "        discriminator.save(save_path + \"dis_e_\"+ str(e+1) + \".h5\")\n",
        "\n",
        "    # save loss \n",
        "    d_loss_path = save_path_loss + \"d_loss_\" + str(e+1) + \"npy\"\n",
        "    g_loss_path = save_path_loss + \"g_loss_\" + str(e+1) + \"npy\"\n",
        "    np.save(d_loss_path, d_losses) \n",
        "    np.save(g_loss_path, g_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2xaU65Vz-mr"
      },
      "outputs": [],
      "source": [
        "g_loss_list = [] # average per epoch list \n",
        "\n",
        "for i in range(10):\n",
        "  # if loss_file.startswith(\"g_loss\"): \n",
        "    g_losses = np.load('/PBL/PBL6/save_loss/d_loss_' + str(i+1)+\"npy.npy\")\n",
        "    g_loss = np.sum(g_losses) /len(g_losses)\n",
        "    g_loss_list.append(g_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "M3hUkNGEUExU",
        "outputId": "b0f3d602-047f-4597-eb15-4fdb3f030314"
      },
      "outputs": [],
      "source": [
        "plt.plot(g_loss_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ilc0nyYoz-om"
      },
      "outputs": [],
      "source": [
        "#Test - perform super resolution using saved generator model\n",
        "from keras.models import load_model\n",
        "from numpy.random import randint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACGJWPhk09X4"
      },
      "outputs": [],
      "source": [
        "generator = load_model('/PBL/PBL6/save_model/gen_e_8.h5', compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "CMWK3Kxf09eM",
        "outputId": "3cc44c83-b95b-4760-d1ed-872699209d67"
      },
      "outputs": [],
      "source": [
        "# plot all three images\n",
        "[X1, X2] = [lr_test, hr_test]\n",
        "\n",
        "# select random example \n",
        "ix = randint(0, len(X1),1)\n",
        "print(len(X1))\n",
        "# src_image, tar_image = X1[[91]], X2[[91]]\n",
        "# ix=[476]\n",
        "src_image, tar_image = X1[ix], X2[ix]\n",
        "print(ix)\n",
        "\n",
        "# generate image from source \n",
        "gen_image = generator.predict(src_image)\n",
        "print(gen_image.shape,src_image.shape)\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(231)\n",
        "plt.title('LR Image')\n",
        "plt.imshow(src_image[0,:,:,:])\n",
        "plt.subplot(232)\n",
        "plt.title('Superresolution')\n",
        "plt.imshow(gen_image[0,:,:,:])\n",
        "plt.subplot(233)\n",
        "plt.title('Orig. HR image')\n",
        "plt.imshow(tar_image[0,:,:,:])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmOPHTSXPtCO",
        "outputId": "19df34db-a07c-44e1-b969-6f9e92cf9b17"
      },
      "outputs": [],
      "source": [
        "# !zip -r '/content/drive/MyDrive/\"PBL.zip\"' '/PBL'"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "b8aa186b9c0ce159ed5d38054f7625a70abeef2cca86fcc854a5ff3e15e8cfab"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
